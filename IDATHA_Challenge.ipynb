{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6zq4L11QzrS"
      },
      "source": [
        "# Generalidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s38dnBTqQzrV"
      },
      "source": [
        "**Sobre la entrega:**\n",
        "* La entrega deberá realizarla a través de correo electrónico a los correos esenturion@idatha.com y eviotti@idatha.com. \n",
        "* Puede entregar más de un archivo, en tal caso sugerimos realizar un archivo comprimido zip conteniéndolos.\n",
        "* Si lo prefiere, puede también subir todo el proyecto a un repositorio Github y compartir la URL al mismo.\n",
        "\n",
        "* Se recomienda separar cada parte del desafío en un Notebook.\n",
        "\n",
        "**Sobre el proyecto**\n",
        "* Le ponemos como restricción al candidato utilizar el lenguaje Python\n",
        "* Para el análisis de datos puede utilizar cualquier libreria Python, aunque recomendamos utilizar la biblioteca [Pandas](https://pandas.pydata.org/).\n",
        "* Le pedimos al candidato que implemente todo el análisis utilizando Jupyter Notebook, Google Colab o similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR9vUqSgQzrW"
      },
      "source": [
        "# Guía para el desafío\n",
        "\n",
        "## Pate 1 - Calidad de datos\n",
        "\n",
        "La idea de esta parte es demostrar de forma práctica, conceptos de calidad y limpieza de datos sobre el dataset provisto. El mismo cuenta con 48895 registros de publicaciones de hospedajes en la plataforma AirBnB para la ciudad de nueva york.\n",
        "\n",
        "El hipotético cliente pretende una vez finalizada la limpieza de datos construir un reporte por barrio de los precios de los hospedajes.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "Columnas del dataset:\n",
        "\n",
        "* id - Identificador de la publicación\n",
        "* name - Nombre de la publicación\n",
        "* host_id - Identificador del usuario que hizo la publicación\n",
        "* host_name - Nombre del usuario que hizo la publicación\n",
        "* neighbourhood_group - Región geográfica de la ciudad\n",
        "* neighbourhood - Barrio\n",
        "* latitude - Latitud\n",
        "* longitude - Longitud\n",
        "* room_type - Tipo de habitación \n",
        "* price - Precio en dólares\n",
        "* minimum_nights - Mínima cantidad de noches\n",
        "* number_of_reviews - Cantidad de revisiones\n",
        "* last_review - Fecha de la última revisión\n",
        "* reviews_per_month - Cantidad promedio de revisiones por mes\n",
        "* calculated_host_listings_count - Cantidad de publicaciones estimadas del usuario\n",
        "* availability_365 - \n",
        "\n",
        "### Se pide\n",
        "\n",
        "1. Cargar el dataset con los datos de AirBnB disponibles para los hospedajes de NYC.\n",
        "2. Inspeccionar los vacios en el dataset:\n",
        "    1. Verificar el tipo de datos de cada columna luego de cargada\n",
        "    2. Contar la cantidad de vacíos, ceros y valores especiales por columna\n",
        "    3. Indicar qué columnas tienen vacíos y como se podrían reparar\n",
        "    4. Modificar las columnas con los datos corregidos\n",
        "3. Inspeccionar el campo de precio:\n",
        "    1. Verificar valores extraños en la columna precio\n",
        "    2. Modificar la columna de precio con los valores corregidos\n",
        "4. Generar un reporte gráfico con los precios por barrios/zonas de la ciudad.\n",
        "    1. Generar una visualización gráfica de los precios\n",
        "    2. Generar estadísticas por barrio, precio máximo, mínimo, promedio, mediano\n",
        "    3. Generar estadísticas por grupos de barrios, precio máximo, mínimo, promedio, mediano\n",
        "    4. ¿Cuál es la completitud de los datos que pudo utilizar para las últimas dos partes? ¿Puede mejorarla de alguna manera? \n",
        "\n",
        "\n",
        "## Parte 2 - Modelos Predictivos\n",
        "\n",
        "El dataset de la segunda parte contiene ejemplos de características físicas y químicas, de algunos vinos de tipo Blanco y Tinto del conocido vino portugués \"Vinho Verde\". Estos ejemplos fueron luego catalogados por algunos expertos con un puntaje entre 0 (muy malo) y 10 (muy bueno). Se considera que un puntaje mayor a 6.5 es bueno.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "Columnas del dataset:\n",
        "\n",
        "* fixed acidity - Acidez fija.\n",
        "* volatile acidity - Acidez volátil.\n",
        "* citric acid - Ácido cítrico.\n",
        "* residual sugar - Azúcar residual.\n",
        "* chlorides - Clorhidratos.\n",
        "* free sulfur dioxide - Dióxido de azufre libre.\n",
        "* total sulfur dioxide - Dióxido de azufre total.\n",
        "* density - Densidad.\n",
        "* pH - Nivel de pH.\n",
        "* sulphates - Sulfatos.\n",
        "* alcohol - Alcohol.\n",
        "\n",
        "**Variable dependiente**\n",
        "\n",
        "* quality (score entre 0 y 10)\n",
        "\n",
        "Algunas consideraciones:\n",
        "\n",
        "* La acidez total y la acidez fija se determinan mediante valoración o mediante potenciometría. La acidez volátil, es la diferencia entre la acidez total y la acidez fija.\n",
        "* El dióxido de azufre total ($TSO_2$) es la porción de $SO_2$ que está libre en el vino más la porción que está ligada a otros químicos en el vino, como aldehídos, pigmentos o azúcares.\n",
        "\n",
        "\n",
        "### Se pide\n",
        "\n",
        "1. Cargar el dataset con los datos de Vinos.\n",
        "2. Inspeccionar los datos en el dataset y realizar un pequeño EDA (Exploratory Data Analysis/Profiling de la información) como hicimos en el curso.\n",
        "3. Estudiar la correlación entre las columnas del dataset y la variable dependiente \"quality\".\n",
        "4. Dividir el dataset entre 70 % train y 30 % test.\n",
        "    1. Entrenar dos algoritmos de modelo de regresión sobre el conjunto de train\n",
        "    2. Reportar $RMSE$ de los modelos para el conjunto de train\n",
        "    3. Decidir cuál de los dos modelos es el mejor. Explique.\n",
        "5. Reportar la métrica $RMSE$ sobre el conjunto de test para ambos modelos. ¿Se cumple qué el modelo elegido en 4 es mejor? Explique muy brevemente.\n",
        "6. Ahora vamos a utilizar un enfoque de clasificación.\n",
        "    1. Entrenar tres modelos de clasificación de los vistos en el curso sobre el conjunto de train.\n",
        "    2. Reportar las métricas _precision, recall y f1-score_ utilizando el reporte de clasificación\n",
        "    3. Decidir cuál de los modelos es el mejor. Explique\n",
        "7. Reportar las métricas _precision, recall y f1-score_ sobre el conjunto de test. ¿Se cumple qué el modelo elegido en 6 es mejor? Explique muy brevemente.\n",
        "8. ¿Cuál modelo de los que entrenó utilizaría? ¿Se le ocurre como comparar el modelo de regresión con los de clasificación? Explique muy brevemente utilizando los resultados obtenidos.\n",
        "\n",
        "    \n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iaop",
      "language": "python",
      "name": "iaop"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "IDATHA_Challenge",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}